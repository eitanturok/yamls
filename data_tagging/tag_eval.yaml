name: data-tagging-3b-nl-doc-eval
gpu_type: a100_40gb
gpu_num: 8
platform: r12z3p2 # this can also be changed in the command line
image: mosaicml/llm-foundry:2.1.0_cu121-e772a47

scheduling:
  priority: low
  preemptible: True
  retry_on_system_failure: true
  max_retries: 0

integrations:
  - integration_type: git_repo
    git_repo: mosaicml/llm-foundry
    pip_install: .[gpu]
    ssh_clone: false

command: |-
  export AWS_PROFILE=data-force-one
  export MOSAICML_PLATFORM=FALSE

  cd llm-foundry/scripts
  composer eval/eval.py /mnt/config/parameters.yaml || (echo "Command failed - killing python" && pkill python && exit 1)

# The below is injected as a YAML file: /mnt/config/parameters.yaml
parameters:

  seed: 1
  precision: amp_fp16
  tokenizer_name: tiktoken
  max_seq_len: 4096
  model_path: s3://data-force-one-datasets/eitan/checkpoints/data-tagging-3b-nl-doc-R0dPNA/ep0-ba14306/ep0-ba14306/  # Model
  models:
  -
    model_name: tag_3b
    # Tokenizer
    tokenizer:
      name: ${tokenizer_name}
      kwargs:
        model_name: gpt-4
    model:
      name: mpt_causal_lm
      init_device: meta
      d_model: 2560
      n_heads: 32
      n_layers: 32
      expansion_ratio: 4
      tokenizer_name: ${tokenizer_name}
      max_seq_len: ${max_seq_len}
      vocab_size: 100352
      no_bias: true
      attn_config:
        alibi: true
        attn_impl: triton
        clip_qkv: 6
    load_path: ${model_path}

  # System
  device_eval_batch_size: 4

  # FSDP config for model sharding
  fsdp_config:
    activation_checkpointing: false
    activation_checkpointing_reentrant: true
    activation_cpu_offload: false
    backward_prefetch: BACKWARD_POST
    forward_prefetch: true
    limit_all_gathers: true
    mixed_precision: PURE
    sharding_strategy: FULL_SHARD
    state_dict_type: sharded
    use_orig_params: false
    verbose: false

  icl_tasks:
  -
    label: squad-wikipedia
    dataset_uri: eval/local_data/reading_comprehension/squad.jsonl
    num_fewshot: [3]
    icl_task_type: language_modeling
    continuation_delimiter: 'This is a high quality wiki: '
  -
    label: squad-no-tag
    dataset_uri: eval/local_data/reading_comprehension/squad.jsonl
    num_fewshot: [3]
    icl_task_type: language_modeling
    continuation_delimiter: 'This is a high quality news: '
  -
    label: squad-no-tag
    dataset_uri: eval/local_data/reading_comprehension/squad.jsonl
    num_fewshot: [3]
    icl_task_type: language_modeling
    continuation_delimiter: ''
